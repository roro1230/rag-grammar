"""
Streamlit GUI for RAG Grammar Teacher
Client for FastAPI RAG service
- Input: Student question in Vietnamese
- Output: Teacher response using RAG API
"""

import streamlit as st
from dotenv import load_dotenv
import os
import json
import requests
from pathlib import Path

# Load environment variables
load_dotenv()
openai_api_key = os.getenv("OPENAI_API_KEY")

if not openai_api_key:
    st.error("‚ö†Ô∏è OPENAI_API_KEY not found in environment. Please add it to .env file.")
    st.stop()

# API configuration
API_BASE_URL = os.getenv("API_BASE_URL", "http://localhost:8000")


# Check if API is running
def check_api_health():
    try:
        response = requests.get(f"{API_BASE_URL}/health", timeout=5)
        return response.status_code == 200
    except:
        return False

if not check_api_health():
    st.error("‚ùå API server is not running. Please start the API server with: `uvicorn api:app --reload`")
    st.stop()


# ============================================================================
# PAGE CONFIG
# ============================================================================
st.set_page_config(
    page_title="üìö Grammar Teacher - RAG",
    page_icon="üìö",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ============================================================================
# SIDEBAR - Configuration & Info
# ============================================================================
with st.sidebar:
    st.markdown("### ‚öôÔ∏è C√†i ƒë·∫∑t")
    
    # Model settings
    model_choice = st.selectbox(
        "Ch·ªçn m√¥ h√¨nh",
        ["gpt-4o", "gpt-4-turbo", "gpt-3.5-turbo"],
        index=0
    )
    
    temperature = st.slider(
        "Temperature (ƒë·ªô s√°ng t·∫°o)",
        min_value=0.0,
        max_value=1.0,
        value=0.3,
        step=0.1,
        help="Th·∫•p = ƒë√°p √°n ch·∫∑t ch·∫Ω, Cao = ƒë√°p √°n s√°ng t·∫°o h∆°n"
    )
    
    k_results = st.slider(
        "S·ªë l∆∞·ª£ng chunks ƒë·ªÉ l·∫•y",
        min_value=1,
        max_value=10,
        value=5,
        step=1,
        help="S·ªë l∆∞·ª£ng ƒëo·∫°n vƒÉn b·∫£n li√™n quan ƒë∆∞·ª£c truy xu·∫•t"
    )
    
    st.markdown("---")
    st.markdown("### ‚ÑπÔ∏è Th√¥ng tin")
    st.info(
        "üí° ·ª®ng d·ª•ng n√†y s·ª≠ d·ª•ng **RAG** (Retrieval-Augmented Generation) "
        "ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi v·ªÅ ng·ªØ ph√°p ti·∫øng Anh d·ª±a tr√™n t√†i li·ªáu."
    )

# ============================================================================
# MAIN CONTENT
# ============================================================================
st.markdown("# üìö Ng·ªØ ph√°p - H·ªá th·ªëng Q&A")
st.markdown("---")

# ============================================================================
# API FUNCTIONS
# ============================================================================
def ask_question_api(question: str, model: str, temperature: float, k_results: int):
    """Send question to RAG API and get response"""
    payload = {
        "question": question,
        "model": model,
        "temperature": temperature,
        "k_results": k_results
    }

    try:
        response = requests.post(f"{API_BASE_URL}/ask", json=payload, timeout=60)
        response.raise_for_status()
        return response.json()
    except requests.exceptions.RequestException as e:
        raise Exception(f"API request failed: {str(e)}")

def update_config_api(model: str = None, temperature: float = None):
    """Update API configuration"""
    payload = {}
    if model:
        payload["model"] = model
    if temperature is not None:
        payload["temperature"] = temperature

    try:
        response = requests.put(f"{API_BASE_URL}/config", json=payload, timeout=10)
        response.raise_for_status()
        return response.json()
    except requests.exceptions.RequestException as e:
        st.warning(f"Failed to update config: {str(e)}")

def get_config_api():
    """Get current API configuration"""
    try:
        response = requests.get(f"{API_BASE_URL}/config", timeout=10)
        response.raise_for_status()
        return response.json()
    except requests.exceptions.RequestException:
        return {"model": "gpt-4o", "temperature": 0.3}

# ============================================================================
# MAIN INPUT/OUTPUT INTERFACE
# ============================================================================
col1, col2 = st.columns([2, 1])

with col1:
    # Input section
    st.markdown("### ‚ùì H·ªèi c√¢u h·ªèi")
    
    # Text input for question
    user_question = st.text_area(
        "Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n v·ªÅ ng·ªØ ph√°p ti·∫øng Anh (b·∫±ng ti·∫øng Vi·ªát):",
        placeholder="V√≠ d·ª•: C√°ch s·ª≠ d·ª•ng th√¨ hi·ªán t·∫°i ho√†n th√†nh l√† g√¨?",
        height=100,
        label_visibility="collapsed"
    )
    
    # Pre-defined examples
    st.markdown("**C√¢u h·ªèi g·ª£i √Ω:**")
    example_questions = [
        "s·ª≠ d·ª•ng th√¨ hi·ªán t·∫°i ho√†n th√†nh nh∆∞ th·∫ø n√†o?",
        "th√¨ t∆∞∆°ng lai ƒë∆°n l√† g√¨?",
        "c√°ch d√πng th√¨ qu√° kh·ª© ti·∫øp di·ªÖn"
    ]
    
    for example in example_questions:
        if st.button(f"üìå {example}", key=example):
            user_question = example

with col2:
    # Settings preview
    st.markdown("### üîß C√†i ƒë·∫∑t hi·ªán t·∫°i")
    st.markdown(f"""
    - **Model**: {model_choice}
    - **Temperature**: {temperature}
    - **Top-k**: {k_results}
    """)

# ============================================================================
# PROCESS QUESTION AND DISPLAY ANSWER
# ============================================================================
if st.button("üöÄ G·ª≠i c√¢u h·ªèi", type="primary", use_container_width=True):
    if not user_question.strip():
        st.warning("‚ö†Ô∏è Vui l√≤ng nh·∫≠p m·ªôt c√¢u h·ªèi.")
    else:
        # Show loading state
        with st.spinner("‚è≥ ƒêang x·ª≠ l√Ω c√¢u h·ªèi..."):
            try:
                # Call API
                api_response = ask_question_api(
                    user_question,
                    model_choice,
                    temperature,
                    k_results
                )

                answer_text = api_response["answer"]
                source_docs = api_response["sources"]

                # Display answer
                st.success("‚úÖ ƒê√£ nh·∫≠n c√¢u tr·∫£ l·ªùi!")
                st.markdown("---")

                st.markdown("### üéì C√¢u tr·∫£ l·ªùi")
                st.markdown(answer_text)

                # Display sources in expandable section
                with st.expander("üìö Xem ngu·ªìn t√†i li·ªáu (Retrieved Context)"):
                    st.markdown(f"**ƒê√£ t√¨m th·∫•y {len(source_docs)} ƒëo·∫°n vƒÉn b·∫£n li√™n quan:**")
                    for i, doc in enumerate(source_docs, 1):
                        st.markdown(f"**Ngu·ªìn {i}:**")
                        if doc.get('metadata') and 'page' in doc['metadata']:
                            st.caption(f"üìÑ Trang: {doc['metadata']['page']}")

                        st.text_area(
                            f"Content {i}",
                            value=doc['content'],
                            height=150,
                            disabled=True,
                            label_visibility="collapsed"
                        )
                        st.markdown("---")

                # Option to save the Q&A
                st.markdown("### üíæ L∆∞u Q&A")
                col_save1, col_save2 = st.columns(2)

                with col_save1:
                    if st.button("üíæ L∆∞u v√†o file", use_container_width=True):
                        qa_entry = {
                            "question": user_question,
                            "answer": answer_text,
                            "model": model_choice,
                            "temperature": temperature
                        }

                        # Append to QA history file
                        qa_file = Path("qa_history.jsonl")
                        with open(qa_file, 'a', encoding='utf-8') as f:
                            f.write(json.dumps(qa_entry, ensure_ascii=False) + '\n')

                        st.success(f"‚úÖ ƒê√£ l∆∞u v√†o `{qa_file}`")

            except Exception as e:
                st.error(f"‚ùå L·ªói khi x·ª≠ l√Ω: {str(e)}")
                st.exception(e)

# ============================================================================
# FOOTER
# ============================================================================
st.markdown("---")
st.markdown(
    """
    <div style='text-align: center; color: gray; font-size: 0.9rem;'>
    üìö RAG Grammar Teacher v2.0 | FastAPI + Streamlit Client
    </div>
    """,
    unsafe_allow_html=True
)
